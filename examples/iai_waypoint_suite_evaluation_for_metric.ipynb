{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65bf467e-7b52-4aef-bad1-72c70888fbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "sys.path.insert(0, \"../torchdrivesim/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89d4bff2-26be-4d2e-8f65-68c1e7669744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kezhang/work/torchdriveenv/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Commercial access denied and fallback to check for academic access.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from typing import Dict, Any, Tuple, List\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from stable_baselines3 import PPO, SAC, TD3, A2C\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "\n",
    "import invertedai\n",
    "from invertedai.common import AgentState, AgentAttributes, Point, TrafficLightState\n",
    "\n",
    "\n",
    "import torchdriveenv\n",
    "from torchdriveenv.gym_env import SingleAgentWrapper, WaypointSuiteEnv\n",
    "from torchdriveenv.env_utils import load_waypoint_suite_data, load_rl_training_config\n",
    "from torchdrivesim.kinematic import KinematicBicycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca1a683-9ec1-4457-baa9-20624a99a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# runs = wandb.Api().runs(path=\"iai/sb3-single-agent-runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "170c29af-f939-4977-968b-383e362b251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"trained_models/TD3_1709879087\"\n",
    "# name = \"TD3_1709879087\"\n",
    "# model_path = f\"{path}/model\"\n",
    "# algorithm = name.split(\"_\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0cf8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iai_drive(location: str, \n",
    "              agent_states: Tensor, \n",
    "              agent_attributes: Tensor, \n",
    "              recurrent_states: List, \n",
    "              traffic_lights_states: Dict = None,\n",
    "              waypoint_for_ego: Tuple = None):\n",
    "\n",
    "    try:\n",
    "        agent_attributes = [AgentAttributes(length=at[0], width=at[1], rear_axis_offset=at[2]) for at in agent_attributes]\n",
    "        if waypoint_for_ego is not None:\n",
    "            agent_attributes[0].waypoint = Point(x=waypoint_for_ego[0], y=waypoint_for_ego[1])\n",
    "        agent_states = [AgentState(center=Point(x=st[0], y=st[1]), orientation=st[2], speed=st[3]) for st in agent_states]\n",
    "        seed = random.randint(1, 10000)\n",
    "        response = invertedai.api.drive(\n",
    "            location=location, agent_states=agent_states, agent_attributes=agent_attributes,\n",
    "            recurrent_states=recurrent_states,\n",
    "            traffic_lights_states=traffic_lights_states,\n",
    "            random_seed=seed\n",
    "        )\n",
    "        agent_states = torch.stack(\n",
    "            [torch.tensor(st.tolist()) for st in response.agent_states], dim=-2\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    return agent_states, response.recurrent_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1afd78fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpertEnv(WaypointSuiteEnv):\n",
    "    def __init__(self, cfg, data):\n",
    "        # at most 100 NPCs\n",
    "#         self.observation_space = gym.spaces.Box(shape=(100, 4), dtype=np.float32)\n",
    "        super().__init__(cfg=cfg, data=data)\n",
    "#         self.observation_space = gym.spaces.Text(max_length=10)\n",
    "        self.observation_space = gym.spaces.Box(shape=(100, 4), low=0, high=255, dtype=np.float32)\n",
    "        \n",
    "\n",
    "    def get_obs(self):\n",
    "        location = f'carla:{\":\".join(self.locations[self.current_waypoint_suite_idx].split(\"_\"))}'\n",
    "\n",
    "        agent_states = self.simulator.get_innermost_simulator().get_state()[\"vehicle\"].squeeze().cpu().numpy()\n",
    "        \n",
    "        agent_attributes = self.simulator._agent_attributes\n",
    "        \n",
    "        recurrent_states = self.simulator._recurrent_states\n",
    "        \n",
    "        traffic_lights_states = self.simulator._traffic_light_controller.current_state_with_name\n",
    "\n",
    "        waypoint_for_ego = self.current_target\n",
    "        \n",
    "        obs = {\"location\": location,\n",
    "               \"agent_states\": agent_states,\n",
    "               \"agent_attributes\": agent_attributes[0],\n",
    "               \"recurrent_states\": recurrent_states[0],\n",
    "               \"traffic_lights_states\": traffic_lights_states,\n",
    "               \"waypoint_for_ego\": waypoint_for_ego}\n",
    "        \n",
    "        with open(\"obs.pkl\", \"wb\") as f:\n",
    "            pickle.dump(obs, f)\n",
    "        \n",
    "#         return \"pickle\"\n",
    "        return np.zeros((100, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9af23666",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expert:\n",
    "    def __init__(self):\n",
    "        self.kinematic_model = KinematicBicycle()\n",
    "    \n",
    "    def predict(self, obs, state=None, episode_start=None, deterministic=None):\n",
    "        with open(\"obs.pkl\", \"rb\") as f:\n",
    "            obs = pickle.load(f)\n",
    "            \n",
    "        states, recurrent_states = iai_drive(location=obs[\"location\"], \n",
    "                                             agent_states=obs[\"agent_states\"], \n",
    "                                             agent_attributes=obs[\"agent_attributes\"], \n",
    "                                             recurrent_states=obs[\"recurrent_states\"], \n",
    "                                             traffic_lights_states=obs[\"traffic_lights_states\"],\n",
    "                                             waypoint_for_ego=obs[\"waypoint_for_ego\"])\n",
    "        \n",
    "        action = self.kinematic_model.fit_action(future_state=states[0], current_state=Tensor(obs[\"agent_states\"][0]))\n",
    "\n",
    "        return [action], states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "742e19e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = load_waypoint_suite_data(\"data/validation_cases.yml\")\n",
    "train_data = load_waypoint_suite_data(\"data/training_cases.yml\")\n",
    "env_config = load_rl_training_config(\"env_configs/rl_training.yml\").env\n",
    "# env_config.render_mode = \"video\"\n",
    "# env_config.video_fov = 450.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a5c20fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnvConfig(ego_only=False, max_environment_steps=200, use_background_traffic=True, terminated_at_infraction=True, seed=None, simulator=TorchDriveConfig(renderer=RendererConfig(backend='default', render_agent_direction=True, left_handed_coordinates=True, highlight_ego_vehicle=True), single_agent_rendering=False, collision_metric=<CollisionMetric.nograd: 'nograd'>, offroad_threshold=0.5, left_handed_coordinates=True), render_mode='rgb_array', video_filename='rendered_video.mp4', video_res=1024, video_fov=500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "381334fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_expert_env():\n",
    "    gym.register('expert-env-v0', \n",
    "                 entry_point=lambda args: SingleAgentWrapper(ExpertEnv(cfg=args['cfg'], data=args['data'])))\n",
    "    env = gym.make('expert-env-v0', args={'cfg': env_config, 'data': train_data})\n",
    "    env = Monitor(env)  \n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d34a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_expert_val_env():\n",
    "    gym.register('expert-env-v0', \n",
    "                 entry_point=lambda args: SingleAgentWrapper(ExpertEnv(cfg=args['cfg'], data=args['data'])))\n",
    "    env = gym.make('expert-env-v0', args={'cfg': env_config, 'data': val_data})\n",
    "    env = Monitor(env)  \n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e5286e9-e9d3-498f-b554-2ad0a804905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_env():\n",
    "#     gym.register('torchdrivesim/waypoint-suite-v0', entry_point=lambda args: SingleAgentWrapper(WaypointSuiteEnv(cfg=args)))\n",
    "#     env = gym.make('torchdrivesim/waypoint-suite-v0', args=waypoint_suite_env_config)\n",
    "#     env = Monitor(env)\n",
    "#     return env\n",
    "\n",
    "# def make_val_env():\n",
    "#     gym.register('torchdrivesim/waypoint-suite-v0', entry_point=lambda args: SingleAgentWrapper(WaypointSuiteEnv(cfg=args)))\n",
    "#     env = gym.make('torchdrivesim/waypoint-suite-v0', args=eval_env_config)\n",
    "#     env = Monitor(env, info_keywords=(\"offroad\", \"collision\", \"traffic_light_violation\"))\n",
    "#     return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbef758b-7e51-4a81-9100-434618fe6902",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "\n",
    "    def __init__(self, model, eval_env, eval_n_episodes: int, deterministic=False, save_path=None, tab=\"eval\"):\n",
    "        super().__init__()\n",
    "        self.eval_n_episodes = eval_n_episodes\n",
    "        self.deterministic = deterministic\n",
    "        self.eval_env = eval_env\n",
    "        self.model = model\n",
    "        self.save_path = save_path\n",
    "        self.tab = tab\n",
    "\n",
    "    def _calc_metrics(self, locals_: Dict[str, Any], globals_: Dict[str, Any]) -> None:\n",
    "        \"\"\"\n",
    "        Callback passed to the  ``evaluate_policy`` function\n",
    "        Called after each step\n",
    "        :param locals_:\n",
    "        :param globals_:\n",
    "        \"\"\"\n",
    "        info = locals_[\"info\"]\n",
    "        if \"psi_smoothness\" not in info:\n",
    "            return\n",
    "        self.psi_smoothness_for_single_episode.append(info[\"psi_smoothness\"])\n",
    "        self.speed_smoothness_for_single_episode.append(info[\"speed_smoothness\"])\n",
    "        if (info[\"offroad\"] > 0) or (info[\"collision\"] > 0) or (info[\"traffic_light_violation\"] > 0) \\\n",
    "                                 or (info[\"is_success\"]):\n",
    "            self.episode_num += 1\n",
    "\n",
    "            if info[\"offroad\"] > 0:\n",
    "                self.offroad_num += 1\n",
    "            if info[\"collision\"] > 0:\n",
    "                self.collision_num += 1\n",
    "            if info[\"traffic_light_violation\"] > 0:\n",
    "                self.traffic_light_violation_num += 1\n",
    "            if info[\"is_success\"]:\n",
    "                self.success_num += 1\n",
    "            self.reached_waypoint_nums.append(info[\"reached_waypoint_num\"])\n",
    "            if len(self.psi_smoothness_for_single_episode) > 0:\n",
    "                self.psi_smoothness.append(sum(self.psi_smoothness_for_single_episode) / len(self.psi_smoothness_for_single_episode))\n",
    "            if len(self.speed_smoothness_for_single_episode) > 0:\n",
    "                self.speed_smoothness.append(sum(self.speed_smoothness_for_single_episode) / len(self.speed_smoothness_for_single_episode))\n",
    "\n",
    "\n",
    "    def evaluate(self) -> bool:\n",
    "        self.episode_num = 0\n",
    "        self.offroad_num = 0\n",
    "        self.collision_num = 0\n",
    "        self.traffic_light_violation_num = 0\n",
    "        self.success_num = 0\n",
    "        self.reached_waypoint_nums = []\n",
    "        self.psi_smoothness = []\n",
    "        self.speed_smoothness = []\n",
    "\n",
    "        mean_episode_reward = 0\n",
    "        mean_episode_length = 0\n",
    "        for i in range(self.eval_n_episodes):\n",
    "            self.psi_smoothness_for_single_episode = []\n",
    "            self.speed_smoothness_for_single_episode = []\n",
    "            episode_rewards, episode_lengths = evaluate_policy(\n",
    "                self.model,\n",
    "                self.eval_env,\n",
    "                n_eval_episodes=1,\n",
    "                deterministic=self.deterministic,\n",
    "                return_episode_rewards=True,\n",
    "                callback=self._calc_metrics,\n",
    "            )\n",
    "            mean_episode_reward += sum(episode_rewards) / len(episode_rewards)\n",
    "            mean_episode_length += sum(episode_lengths) / len(episode_lengths)\n",
    "\n",
    "        mean_episode_reward /= self.eval_n_episodes\n",
    "        mean_episode_length /= self.eval_n_episodes\n",
    "\n",
    "        print(f\"mean_episode_reward\", mean_episode_reward)\n",
    "        print(f\"mean_episode_length\", mean_episode_length)\n",
    "\n",
    "        print(f\"offroad_rate\", self.offroad_num / self.eval_n_episodes)\n",
    "        print(f\"collision_rate\", self.collision_num / self.eval_n_episodes)\n",
    "        print(f\"traffic_light_violation_rate\", self.traffic_light_violation_num / self.eval_n_episodes)\n",
    "        print(f\"success_percentage\", self.success_num / self.eval_n_episodes)\n",
    "        print(f\"reached_waypoint_num\", sum(self.reached_waypoint_nums) / self.eval_n_episodes)\n",
    "        print(f\"psi_smoothness\", sum(self.psi_smoothness) / self.eval_n_episodes)\n",
    "        print(f\"speed_smoothness\", sum(self.speed_smoothness) / self.eval_n_episodes)\n",
    "\n",
    "        if self.save_path is not None:\n",
    "            metrics = {\"mean_episode_reward\": mean_episode_reward,\n",
    "                       \"mean_episode_length\": mean_episode_length,\n",
    "                       \"offroad_rate\": self.offroad_num / self.eval_n_episodes,\n",
    "                       \"collision_rate\": self.collision_num / self.eval_n_episodes,\n",
    "                       \"traffic_light_violation_rate\": self.traffic_light_violation_num / self.eval_n_episodes,\n",
    "                       \"success_percentage\": self.success_num / self.eval_n_episodes,\n",
    "                       \"reached_waypoint_num\": sum(self.reached_waypoint_nums) / self.eval_n_episodes,\n",
    "                       \"psi_smoothness\": sum(self.psi_smoothness) / self.eval_n_episodes,\n",
    "                       \"speed_smoothness\": sum(self.speed_smoothness) / self.eval_n_episodes}\n",
    "            \n",
    "            with open(f'{self.save_path}/metrics_{self.tab}.json', 'w') as f:\n",
    "                json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479c84fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torchdriveenv.gym_env:seed: 2796306508\n",
      "INFO:torchdriveenv.gym_env:    def get_reward(self):\n",
      "        x = self.simulator.get_state()[..., 0]\n",
      "        y = self.simulator.get_state()[..., 1]\n",
      "        psi = self.simulator.get_state()[..., 2]\n",
      "\n",
      "        d = math.dist((x, y), (self.last_x, self.last_y)) if (self.last_x is not None) and (self.last_y is not None) else 0\n",
      "        distance_reward = 1 if d > 0.5 else 0\n",
      "        psi_reward = (1 - math.cos(psi - self.last_psi)) * (-20.0) if (self.last_psi is not None) else 0\n",
      "        if self.check_reach_target():\n",
      "            reach_target_reward = 10\n",
      "            self.reached_waypoint_num += 1\n",
      "        else:\n",
      "            reach_target_reward = 0\n",
      "        r = torch.zeros_like(x)\n",
      "        r += reach_target_reward + distance_reward + psi_reward\n",
      "        return r\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for validation: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kezhang/work/torchdriveenv/.venv/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/home/kezhang/work/torchdriveenv/.venv/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/home/kezhang/work/torchdriveenv/.venv/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:228: UserWarning: \u001b[33mWARN: Expects `terminated` signal to be a boolean, actual type: <class 'torch.Tensor'>\u001b[0m\n",
      "  logger.warn(\n",
      "/home/kezhang/work/torchdriveenv/.venv/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/home/kezhang/work/torchdriveenv/.venv/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/home/kezhang/work/torchdriveenv/.venv/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:246: UserWarning: \u001b[33mWARN: The reward returned by `step()` must be a float, int, np.integer or np.floating, actual type: <class 'torch.Tensor'>\u001b[0m\n",
      "  logger.warn(\n",
      "/home/kezhang/work/torchdriveenv/.venv/lib/python3.10/site-packages/gymnasium/envs/registration.py:694: UserWarning: \u001b[33mWARN: Overriding environment expert-env-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n",
      "INFO:torchdriveenv.gym_env:seed: 1378764133\n",
      "INFO:torchdriveenv.gym_env:    def get_reward(self):\n",
      "        x = self.simulator.get_state()[..., 0]\n",
      "        y = self.simulator.get_state()[..., 1]\n",
      "        psi = self.simulator.get_state()[..., 2]\n",
      "\n",
      "        d = math.dist((x, y), (self.last_x, self.last_y)) if (self.last_x is not None) and (self.last_y is not None) else 0\n",
      "        distance_reward = 1 if d > 0.5 else 0\n",
      "        psi_reward = (1 - math.cos(psi - self.last_psi)) * (-20.0) if (self.last_psi is not None) else 0\n",
      "        if self.check_reach_target():\n",
      "            reach_target_reward = 10\n",
      "            self.reached_waypoint_num += 1\n",
      "        else:\n",
      "            reach_target_reward = 0\n",
      "        r = torch.zeros_like(x)\n",
      "        r += reach_target_reward + distance_reward + psi_reward\n",
      "        return r\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_episode_reward 7.421078\n",
      "mean_episode_length 65.2\n",
      "offroad_rate 0.7\n",
      "collision_rate 0.0\n",
      "traffic_light_violation_rate 0.0\n",
      "success_percentage 0.3\n",
      "reached_waypoint_num 0.3\n",
      "psi_smoothness 0.11129111062912715\n",
      "speed_smoothness 0.826675123946087\n",
      "for training: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:invertedai.utils:Retrying /drive: Status 503, Message {\"message\":\"The server is not able to handle the request at this moment, please try again later.\"} Retry #1, Backoff 1 seconds\n"
     ]
    }
   ],
   "source": [
    "model = Expert()\n",
    "path = \"iai_evaluation\"\n",
    "\n",
    "        \n",
    "print(\"for validation: \")\n",
    "eval_val_env = DummyVecEnv([make_expert_val_env])\n",
    "# eval_val_env = VecFrameStack(eval_val_env, n_stack=3, channels_order=\"first\")\n",
    "\n",
    "eval_val = Evaluation(model, eval_val_env, eval_n_episodes=10, deterministic=True, save_path=path, tab=\"validation\")\n",
    "eval_val.evaluate()\n",
    "\n",
    "\n",
    "print(\"for training: \")\n",
    "eval_train_env = DummyVecEnv([make_expert_env])\n",
    "# eval_train_env = VecFrameStack(eval_train_env, n_stack=3, channels_order=\"first\")\n",
    "\n",
    "eval_train = Evaluation(model, eval_train_env, eval_n_episodes=10, deterministic=True, save_path=path, tab=\"train\")\n",
    "eval_train.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caed2e7-7a3c-440c-909b-ef50b0ed99a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# waypoint_suite_env_config = load_waypoint_suite_env_config(\"env_configs/training_config.yml\")\n",
    "# eval_env_config = load_waypoint_suite_env_config(\"env_configs/new_new_waypoint_suite_env_config.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42ec819-2311-442f-a2a9-e2a63a1f88f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# waypoint_suite_env_config.iai_gym.ego_only = True\n",
    "# waypoint_suite_env_config.iai_gym.use_background_traffic = False\n",
    "# eval_env_config.iai_gym.ego_only = True\n",
    "# eval_env_config.iai_gym.use_background_traffic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51802e86-bf07-451f-993a-1193fc940c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_agent_runs = [\"SAC_1709170872\", \"SAC_1709176155\", \"SAC_1709206540\", \"SAC_1709206402\"]\n",
    "\n",
    "# for run in runs:\n",
    "#     if run.name not in single_agent_runs:\n",
    "#         continue\n",
    "#     print(run.name)\n",
    "#     path = f\"trained_models/{run.name}\"\n",
    "#     name = run.name\n",
    "#     model_path = f\"{path}/model\"\n",
    "#     algorithm = name.split(\"_\")[0]\n",
    "#     if not os.path.exists(path):\n",
    "#         os.mkdir(path)\n",
    "#     run.file(\"model.zip\").download(root=path, replace=True)\n",
    "#     if algorithm == \"SAC\":\n",
    "#         model = SAC.load(model_path)\n",
    "    \n",
    "#     if algorithm == \"PPO\":\n",
    "#         model = PPO.load(model_path)\n",
    "    \n",
    "#     if algorithm == \"A2C\":\n",
    "#         model = A2C.load(model_path)\n",
    "        \n",
    "#     if algorithm == \"TD3\":\n",
    "#         model = TD3.load(model_path)\n",
    "        \n",
    "#     print(\"for validation: \")\n",
    "#     eval_val_env = SubprocVecEnv([make_val_env])\n",
    "#     eval_val_env = VecFrameStack(eval_val_env, n_stack=3, channels_order=\"first\")\n",
    "    \n",
    "#     eval_val = Evaluation(model, eval_val_env, eval_n_episodes=10, deterministic=True, save_path=path, tab=\"validation\")\n",
    "#     eval_val.evaluate()\n",
    "    \n",
    "#     print(\"for training: \")\n",
    "#     eval_train_env = SubprocVecEnv([make_env])\n",
    "#     eval_train_env = VecFrameStack(eval_train_env, n_stack=3, channels_order=\"first\")\n",
    "    \n",
    "#     eval_train = Evaluation(model, eval_train_env, eval_n_episodes=10, deterministic=True, save_path=path, tab=\"train\")\n",
    "#     eval_train.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchdriveenv",
   "language": "python",
   "name": "torchdriveenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
